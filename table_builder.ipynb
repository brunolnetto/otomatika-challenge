{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file json_responses/news_160161.json: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "import json\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import requests\n",
    "\n",
    "def search_and_save(\n",
    "    url_template: str, search_term: str, output_dir: str\n",
    "):\n",
    "    # Replace the placeholder with the search term\n",
    "    search_url = url_template.format(search_term=search_term)\n",
    "    logging.info(f\"Searching for '{search_term}' using {search_url}\")\n",
    "    \n",
    "    # Create directory to save the search results pages\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Extract the domain name to use as part of the filename\n",
    "    domain = search_url.split('/')[2]\n",
    "    \n",
    "    # Fetch the search results page\n",
    "    try:\n",
    "        response = requests.get(search_url)\n",
    "        \n",
    "        # Raise error for bad responses (4xx or 5xx)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.info(f\"Error fetching search results: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Save the search results page to the output directory\n",
    "    output_filepath = os.path.join(output_dir, f\"{domain}_search_{search_term}.html\")\n",
    "    \n",
    "    with open(output_filepath, 'wb') as outfile:\n",
    "        outfile.write(response.content)\n",
    "\n",
    "    info_msg=f\"Fetched search results for '{search_term}' from {search_url} and saved as {output_filepath}\"\n",
    "    logging.info(info_msg)\n",
    "\n",
    "    return output_filepath\n",
    "\n",
    "def download_json_responses(\n",
    "    input_file: str, pattern: str, output_dir: str\n",
    "):\n",
    "    # Check if the input file exists\n",
    "    if not os.path.isfile(input_file):\n",
    "        print(f\"Input file '{input_file}' not found.\")\n",
    "        return\n",
    "    \n",
    "    output_file_prefix = 'news'\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Read input file and find all URLs matching the pattern\n",
    "    with open(input_file, 'r') as file:\n",
    "        links = re.findall(pattern, file.read())\n",
    "\n",
    "    # Download each link using requests library\n",
    "    for link in links:\n",
    "        # Extract the news number from the link\n",
    "        news_number = re.search(r'[0-9]+$', link).group()\n",
    "\n",
    "        # Construct the output file path\n",
    "        filename = f\"{output_file_prefix}_{news_number}.json\"\n",
    "        output_file = os.path.join(output_dir, filename)\n",
    "\n",
    "        # Perform GET request to download JSON data\n",
    "        response = requests.get(link)\n",
    "\n",
    "        # Check if the request was successful (status code 200)\n",
    "        if response.status_code == 200:\n",
    "            # Save the JSON response to file\n",
    "            with open(output_file, 'wb') as outfile:\n",
    "                outfile.write(response.content)\n",
    "            \n",
    "            logging.info(f\"Downloaded {link} to {output_file}\")\n",
    "        else:\n",
    "            logging.error(f\"Failed to download {link}. Status code: {response.status_code}\")\n",
    "\n",
    "    logging.info(f\"Downloaded JSON responses from links in {input_file} to {output_dir}/{output_file_prefix}_*.json\")\n",
    "\n",
    "\n",
    "def extract_data(source_folder, search_phrases):\n",
    "    # Assuming 'data' contains the JSON data you provided earlier\n",
    "    filenames = listdir(source_folder)\n",
    "    filenames = [f for f in filenames if f.endswith('.json')]\n",
    "\n",
    "    # Initialize lists to store extracted data\n",
    "    ids = []\n",
    "    titles = []\n",
    "    dates = []\n",
    "    descriptions = []\n",
    "    picture_filenames = []\n",
    "    search_phrase_counts = []\n",
    "    contains_money = []\n",
    "\n",
    "    for filename in filenames:\n",
    "        file_path=f'{source_folder}/{filename}'\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                # Extract basic fields\n",
    "                id_ = filename.split('.')[0].split('_')[-1]\n",
    "                title = data['title']\n",
    "                date = data['publication_date']\n",
    "                description = data.get('description', '')\n",
    "                picture_filename = ''\n",
    "                for image_data in data.get('lead_asset', []):\n",
    "                    if image_data['type'] == 'lead_image':    \n",
    "                        picture_filename = image_data['value']['image']['file']\n",
    "                        break \n",
    "                \n",
    "                # Count search phrases in title and description\n",
    "                title_search_count = sum(1 for phrase in search_phrases if phrase in title)\n",
    "                description_search_count = sum(1 for phrase in search_phrases if phrase in description)\n",
    "\n",
    "                # Check if title or description contains any money mention\n",
    "                # Regular expression pattern to detect money formats\n",
    "                money_pattern = r'\\$[\\d,]+(\\.\\d+)?|\\d+\\s(dollars|USD)'\n",
    "                \n",
    "                title_has_money = bool(re.search(money_pattern, title))\n",
    "                description_has_money = bool(re.search(money_pattern, description))\n",
    "\n",
    "                # Store extracted data in lists\n",
    "                ids.append(id_)\n",
    "                titles.append(title)\n",
    "                dates.append(date)\n",
    "                descriptions.append(description)\n",
    "                picture_filenames.append(picture_filename)\n",
    "                search_phrase_counts.append(title_search_count + description_search_count)\n",
    "                contains_money.append(title_has_money or description_has_money)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f'Error processing file {file_path}: {e}')\n",
    "\n",
    "    # Create a Pandas DataFrame\n",
    "    df_data={\n",
    "        'id': ids,\n",
    "        'title': titles,\n",
    "        'date': dates,\n",
    "        'description': descriptions,\n",
    "        'picture_filename': picture_filenames,\n",
    "        'search_phrase_count': search_phrase_counts,\n",
    "        'contains_money': contains_money\n",
    "    }\n",
    "    df = pd.DataFrame(df_data)\n",
    "\n",
    "    return df\n",
    "\n",
    "def setup_logging():\n",
    "    log_format = '%(asctime)s - %(message)s'\n",
    "    logging.basicConfig(level=logging.INFO, format=log_format)\n",
    "\n",
    "# Function to generate mask for given number of months\n",
    "def generate_month_mask(series_: pd.Series, num_months: int):\n",
    "    import pytz\n",
    "    from datetime import datetime\n",
    "\n",
    "    num_months = max(0, num_months-1)\n",
    "    \n",
    "    # Ensure series_ is converted to datetime with UTC timezone\n",
    "    if not pd.api.types.is_datetime64_any_dtype(series_):\n",
    "        series_ = pd.to_datetime(series_, utc=True)\n",
    "    elif series_.dtype != 'datetime64[ns, UTC]':\n",
    "        series_ = series_.dt.tz_localize('UTC')\n",
    "    \n",
    "    # Get the current date and convert to UTC timezone-naive if needed\n",
    "    current_date = datetime.now(pytz.utc)\n",
    "    \n",
    "    # Calculate the start date based on the number of months\n",
    "    start_date = current_date - pd.DateOffset(months=num_months)\n",
    "    \n",
    "    # Create a mask to check if the date is within the specified range\n",
    "    mask = (series_ >= start_date) & (series_ <= current_date)\n",
    "    \n",
    "    return mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>picture_filename</th>\n",
       "      <th>search_phrase_count</th>\n",
       "      <th>contains_money</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>160144</td>\n",
       "      <td>At a Queens school, migrant kids gain melodies...</td>\n",
       "      <td>2024-07-03 05:01:00-04:00</td>\n",
       "      <td>The Academy for New Americans creates a welcom...</td>\n",
       "      <td>https://images-prod.gothamist.com/original_ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>160065</td>\n",
       "      <td>NYC’s graduating ‘COVID babies’ reflect as hig...</td>\n",
       "      <td>2024-06-26 05:01:00-04:00</td>\n",
       "      <td>Gothamist interviewed students who are speakin...</td>\n",
       "      <td>https://images-prod.gothamist.com/original_ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>160130</td>\n",
       "      <td>Pamphlets and bullhorns: G train riders naviga...</td>\n",
       "      <td>2024-07-01 17:43:10.301503-04:00</td>\n",
       "      <td>The MTA says the closure is necessary to make ...</td>\n",
       "      <td>https://images-prod.gothamist.com/original_ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>159967</td>\n",
       "      <td>Automated ticketing of drivers blocking MTA bu...</td>\n",
       "      <td>2024-06-17 14:05:00-04:00</td>\n",
       "      <td>Drivers parked or double parked at bus stops w...</td>\n",
       "      <td>https://images-prod.gothamist.com/original_ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>160039</td>\n",
       "      <td>NYC officials plan rally to stop budget cuts t...</td>\n",
       "      <td>2024-06-22 21:56:00-04:00</td>\n",
       "      <td>As libraries stare down $58.3 million in cuts ...</td>\n",
       "      <td>https://images-prod.gothamist.com/original_ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>160239</td>\n",
       "      <td>NYC nightlife legend DJ Rekha brings 'Basement...</td>\n",
       "      <td>2024-07-11 11:01:08.444117-04:00</td>\n",
       "      <td>“Every time I try to get out, they pull me bac...</td>\n",
       "      <td>https://images-prod.gothamist.com/original_ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>160138</td>\n",
       "      <td>Was that bang a gunshot or a firework? How New...</td>\n",
       "      <td>2024-07-03 06:00:00-04:00</td>\n",
       "      <td>While both acts are generally illegal in New Y...</td>\n",
       "      <td>https://images-prod.gothamist.com/original_ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>160228</td>\n",
       "      <td>NYC's massive Link5G towers aren't actually pr...</td>\n",
       "      <td>2024-07-11 06:31:00-04:00</td>\n",
       "      <td>Almost all of the towers stand empty, CityBrid...</td>\n",
       "      <td>https://images-prod.gothamist.com/original_ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>160100</td>\n",
       "      <td>Brooklyn and Queens prepare yourselves: The G ...</td>\n",
       "      <td>2024-06-28 11:01:00-04:00</td>\n",
       "      <td>Not since the MTA announced the closure of L t...</td>\n",
       "      <td>https://images-prod.gothamist.com/original_ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>160147</td>\n",
       "      <td>NJ lawmaker looks to ban algorithms blamed for...</td>\n",
       "      <td>2024-07-06 09:01:04.483498-04:00</td>\n",
       "      <td>Critics say using software like RealPage's ser...</td>\n",
       "      <td>https://images-prod.gothamist.com/original_ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>160080</td>\n",
       "      <td>New rules are coming for PFAS in drinking wate...</td>\n",
       "      <td>2024-06-27 05:00:57.728125-04:00</td>\n",
       "      <td>A Gothamist analysis shows that the drinking w...</td>\n",
       "      <td>https://images-prod.gothamist.com/original_ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>160114</td>\n",
       "      <td>Wait time for ambulances in NYC is the longest...</td>\n",
       "      <td>2024-07-01 11:00:00-04:00</td>\n",
       "      <td>The city's emergency medical agency blames hig...</td>\n",
       "      <td>https://images-prod.gothamist.com/original_ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>160216</td>\n",
       "      <td>After 4 beach drownings, Mayor Adams dismisses...</td>\n",
       "      <td>2024-07-09 16:39:00-04:00</td>\n",
       "      <td>“It’s more about education,” the mayor said on...</td>\n",
       "      <td>https://images-prod.gothamist.com/original_ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>159983</td>\n",
       "      <td>Extra Extra: NYC finally has a buyer for a dec...</td>\n",
       "      <td>2024-06-18 15:00:59.220083-04:00</td>\n",
       "      <td>Because that took longer than expected, here a...</td>\n",
       "      <td>https://images-prod.gothamist.com/original_ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>160206</td>\n",
       "      <td>JFK Airport’s newest ride? Not planes, but sel...</td>\n",
       "      <td>2024-07-09 06:31:00-04:00</td>\n",
       "      <td>The Port Authority says it’s rolling out passe...</td>\n",
       "      <td>https://images-prod.gothamist.com/original_ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "7   160144  At a Queens school, migrant kids gain melodies...   \n",
       "9   160065  NYC’s graduating ‘COVID babies’ reflect as hig...   \n",
       "10  160130  Pamphlets and bullhorns: G train riders naviga...   \n",
       "21  159967  Automated ticketing of drivers blocking MTA bu...   \n",
       "28  160039  NYC officials plan rally to stop budget cuts t...   \n",
       "31  160239  NYC nightlife legend DJ Rekha brings 'Basement...   \n",
       "35  160138  Was that bang a gunshot or a firework? How New...   \n",
       "56  160228  NYC's massive Link5G towers aren't actually pr...   \n",
       "69  160100  Brooklyn and Queens prepare yourselves: The G ...   \n",
       "75  160147  NJ lawmaker looks to ban algorithms blamed for...   \n",
       "78  160080  New rules are coming for PFAS in drinking wate...   \n",
       "80  160114  Wait time for ambulances in NYC is the longest...   \n",
       "84  160216  After 4 beach drownings, Mayor Adams dismisses...   \n",
       "85  159983  Extra Extra: NYC finally has a buyer for a dec...   \n",
       "99  160206  JFK Airport’s newest ride? Not planes, but sel...   \n",
       "\n",
       "                                date  \\\n",
       "7          2024-07-03 05:01:00-04:00   \n",
       "9          2024-06-26 05:01:00-04:00   \n",
       "10  2024-07-01 17:43:10.301503-04:00   \n",
       "21         2024-06-17 14:05:00-04:00   \n",
       "28         2024-06-22 21:56:00-04:00   \n",
       "31  2024-07-11 11:01:08.444117-04:00   \n",
       "35         2024-07-03 06:00:00-04:00   \n",
       "56         2024-07-11 06:31:00-04:00   \n",
       "69         2024-06-28 11:01:00-04:00   \n",
       "75  2024-07-06 09:01:04.483498-04:00   \n",
       "78  2024-06-27 05:00:57.728125-04:00   \n",
       "80         2024-07-01 11:00:00-04:00   \n",
       "84         2024-07-09 16:39:00-04:00   \n",
       "85  2024-06-18 15:00:59.220083-04:00   \n",
       "99         2024-07-09 06:31:00-04:00   \n",
       "\n",
       "                                          description  \\\n",
       "7   The Academy for New Americans creates a welcom...   \n",
       "9   Gothamist interviewed students who are speakin...   \n",
       "10  The MTA says the closure is necessary to make ...   \n",
       "21  Drivers parked or double parked at bus stops w...   \n",
       "28  As libraries stare down $58.3 million in cuts ...   \n",
       "31  “Every time I try to get out, they pull me bac...   \n",
       "35  While both acts are generally illegal in New Y...   \n",
       "56  Almost all of the towers stand empty, CityBrid...   \n",
       "69  Not since the MTA announced the closure of L t...   \n",
       "75  Critics say using software like RealPage's ser...   \n",
       "78  A Gothamist analysis shows that the drinking w...   \n",
       "80  The city's emergency medical agency blames hig...   \n",
       "84  “It’s more about education,” the mayor said on...   \n",
       "85  Because that took longer than expected, here a...   \n",
       "99  The Port Authority says it’s rolling out passe...   \n",
       "\n",
       "                                     picture_filename  search_phrase_count  \\\n",
       "7   https://images-prod.gothamist.com/original_ima...                    0   \n",
       "9   https://images-prod.gothamist.com/original_ima...                    0   \n",
       "10  https://images-prod.gothamist.com/original_ima...                    0   \n",
       "21  https://images-prod.gothamist.com/original_ima...                    0   \n",
       "28  https://images-prod.gothamist.com/original_ima...                    0   \n",
       "31  https://images-prod.gothamist.com/original_ima...                    0   \n",
       "35  https://images-prod.gothamist.com/original_ima...                    0   \n",
       "56  https://images-prod.gothamist.com/original_ima...                    0   \n",
       "69  https://images-prod.gothamist.com/original_ima...                    0   \n",
       "75  https://images-prod.gothamist.com/original_ima...                    0   \n",
       "78  https://images-prod.gothamist.com/original_ima...                    0   \n",
       "80  https://images-prod.gothamist.com/original_ima...                    0   \n",
       "84  https://images-prod.gothamist.com/original_ima...                    0   \n",
       "85  https://images-prod.gothamist.com/original_ima...                    0   \n",
       "99  https://images-prod.gothamist.com/original_ima...                    0   \n",
       "\n",
       "    contains_money  \n",
       "7            False  \n",
       "9            False  \n",
       "10           False  \n",
       "21            True  \n",
       "28            True  \n",
       "31           False  \n",
       "35           False  \n",
       "56           False  \n",
       "69           False  \n",
       "75           False  \n",
       "78           False  \n",
       "80           False  \n",
       "84           False  \n",
       "85           False  \n",
       "99           False  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[generate_month_mask(df['date'], 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2024\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RangeIndex' object has no attribute 'month'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(pd\u001b[38;5;241m.\u001b[39mto_datetime)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mgenerate_month_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[73], line 169\u001b[0m, in \u001b[0;36mgenerate_month_mask\u001b[0;34m(series_, num_months)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28mprint\u001b[39m(start_month)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28mprint\u001b[39m(start_year)\n\u001b[0;32m--> 169\u001b[0m series_month \u001b[38;5;241m=\u001b[39m \u001b[43mseries_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmonth\u001b[49m\n\u001b[1;32m    170\u001b[0m series_year \u001b[38;5;241m=\u001b[39m series_\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39myear\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# Create a mask to check if the date is within the specified range\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RangeIndex' object has no attribute 'month'"
     ]
    }
   ],
   "source": [
    "df['date']=df['date'].apply(pd.to_datetime)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file json_responses/news_160239.json: Expecting value: line 5 column 1 (char 4)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data \"2024-03-25T15:42:00-04:00\" doesn't match format \"%Y-%m-%dT%H:%M:%S.%f%z\", at position 3. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Filter the data based on the number of months\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m filter_mask \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_month_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonths_horizon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m df_filtered\u001b[38;5;241m=\u001b[39mdf[filter_mask]\n\u001b[1;32m     45\u001b[0m df_filtered\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[125], line 161\u001b[0m, in \u001b[0;36mgenerate_month_mask\u001b[0;34m(series_, num_months)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# Ensure series_ is converted to datetime with UTC timezone\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_datetime64_any_dtype(series_):\n\u001b[0;32m--> 161\u001b[0m     series_ \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m series_\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime64[ns, UTC]\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    163\u001b[0m     series_ \u001b[38;5;241m=\u001b[39m series_\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTC\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:1067\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1067\u001b[0m         values \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[0;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[1;32m    436\u001b[0m     arg,\n\u001b[1;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    442\u001b[0m )\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[0;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[1;32m    457\u001b[0m     arg,\n\u001b[1;32m    458\u001b[0m     name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[1;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mstrptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: time data \"2024-03-25T15:42:00-04:00\" doesn't match format \"%Y-%m-%dT%H:%M:%S.%f%z\", at position 3. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "import re\n",
    "import shutil\n",
    "\n",
    "# URL template with placeholders for the search term\n",
    "url_template = \"https://gothamist.com/search?q={search_term}\"\n",
    "search_term='technology'\n",
    "months_horizon=3\n",
    "\n",
    "setup_logging()\n",
    "\n",
    "logging.info(f'Searching for {search_term} on {url_template} and saving the search results')\n",
    "filepath = search_and_save(url_template, search_term, 'search_results')\n",
    "\n",
    "if filepath:\n",
    "    # Define the pattern to match URLs\n",
    "    pattern = r'https://api-prod.gothamist.com/api/v2/pages/[0-9]{4,}'\n",
    "\n",
    "    logging.info('Downloading JSON responses')\n",
    "    download_json_responses(filepath, pattern, 'json_responses')\n",
    "\n",
    "shutil.rmtree('search_results')\n",
    "\n",
    "filenames = listdir('json_responses')\n",
    "\n",
    "if not filenames:\n",
    "    logging.info('No JSON responses to process. Exiting...')\n",
    "    exit()\n",
    "else: \n",
    "    # Extract data from JSON responses\n",
    "    logging.info('Extracting data')\n",
    "    df = extract_data('json_responses', [search_term])\n",
    "\n",
    "    shutil.rmtree('json_responses')\n",
    "\n",
    "    # Save the extracted data to a CSV file\n",
    "    logging.info(f\"Saving extracted data to 'output.csv'\")\n",
    "    output_folder='output'\n",
    "    output_filename='output.csv'\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Filter the data based on the number of months\n",
    "    filter_mask = generate_month_mask(df['date'], months_horizon)\n",
    "    df_filtered=df[filter_mask]\n",
    "\n",
    "    df_filtered.to_csv(f'{output_folder}/{output_filename}', index=False)\n",
    "    logging.info('Done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
